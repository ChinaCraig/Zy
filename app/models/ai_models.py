import requests
import json
import time
from app.app_config import config
from app.models.chat_models import chat_archive_service

class AIModelManager:
    """AIæ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.conversation_history = []
        self.user_identity = None  # ç”¨æˆ·èº«ä»½ä¿¡æ¯
        self.is_identity_verified = False  # èº«ä»½éªŒè¯çŠ¶æ€
        self.chat_terminated = False  # èŠå¤©æ˜¯å¦è¢«ç»ˆæ­¢
        self.session_info = {}  # ä¼šè¯ä¿¡æ¯ï¼ˆæµè§ˆå™¨ã€IPç­‰ï¼‰
    
    def add_to_history(self, user_message, ai_response):
        """æ·»åŠ å¯¹è¯åˆ°å†å²è®°å½•"""
        self.conversation_history.append({
            'user': user_message,
            'assistant': ai_response,
            'timestamp': time.time()
        })
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(self.conversation_history) > config.max_history:
            self.conversation_history = self.conversation_history[-config.max_history:]
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°èŠå¤©å­˜å‚¨ä¸Šé™
        if len(self.conversation_history) >= config.chat_storage_limit:
            self.chat_terminated = True
    
    def get_system_prompt(self):
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        style_prompts = {
            'formal': 'è¯·ç”¨æ­£å¼ã€ä¸“ä¸šçš„è¯­è¨€å›å¤ã€‚',
            'casual': 'è¯·ç”¨è½»æ¾ã€å‹å¥½çš„è¯­è¨€å›å¤ã€‚',
            'cute': 'è¯·ç”¨å¯çˆ±ã€ä¿çš®çš„è¯­è¨€å›å¤ï¼Œå¯ä»¥é€‚å½“ä½¿ç”¨é¢œæ–‡å­—ã€‚'
        }
        
        system_prompt = f"""
ä½ æ˜¯{config.virtual_human_name}ï¼Œ{config.personality}ã€‚
{style_prompts.get(config.reply_style, '')}
è¯·ä¿æŒå›å¤ç®€æ´æœ‰è¶£ï¼Œé•¿åº¦æ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚
"""
        
        if config.enable_emotions:
            system_prompt += "è¯·åœ¨å›å¤ä¸­è¡¨è¾¾é€‚å½“çš„æƒ…æ„Ÿï¼Œè®©å¯¹è¯æ›´åŠ ç”ŸåŠ¨ã€‚"
        
        return system_prompt.strip()
    
    def verify_identity(self, user_input):
        """éªŒè¯ç”¨æˆ·èº«ä»½"""
        if not user_input or not user_input.strip():
            return False, "è¯·è¾“å…¥æ‚¨çš„å§“åã€‚"
        
        name = user_input.strip()
        
        # åŸºæœ¬éªŒè¯è§„åˆ™
        if len(name) > 20:
            return False, "å§“åå¤ªé•¿äº†ï¼Œè¯·è¾“å…¥ä¸€ä¸ªç®€çŸ­çš„åå­—ã€‚"
        
        if len(name) < 1:
            return False, "è¯·è¾“å…¥æ‚¨çš„å§“åã€‚"
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡å¤šç‰¹æ®Šå­—ç¬¦
        special_chars = '!@#$%^&*()_+-=[]{}|;:,.<>?/~`'
        special_count = sum(1 for char in name if char in special_chars)
        if special_count > 2:
            return False, "å§“åä¸­ç‰¹æ®Šå­—ç¬¦å¤ªå¤šï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ­£å¸¸çš„åå­—ã€‚"
        
        # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯æ•°å­—
        if name.isdigit():
            return False, "è¯·è¾“å…¥æ‚¨çš„å§“åï¼Œè€Œä¸æ˜¯çº¯æ•°å­—ã€‚"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„æ— æ„ä¹‰è¾“å…¥
        meaningless_inputs = [
            'test', 'testing', 'æµ‹è¯•', 'aaa', 'abc', 
            'hello', 'hi', 'ä½ å¥½', 'qwerty', 'asdf', '...', 'ã€‚ã€‚ã€‚',
            'user', 'admin', 'root', 'guest'
        ]
        if name.lower() in meaningless_inputs:
            return False, "è¯·è¾“å…¥æ‚¨çš„çœŸå®å§“åæˆ–æ˜µç§°ï¼Œè€Œä¸æ˜¯æµ‹è¯•å†…å®¹ã€‚"
        
        # æ£€æŸ¥æ˜¯å¦å…¨æ˜¯ç›¸åŒå­—ç¬¦
        if len(set(name)) == 1 and len(name) > 3:
            return False, "è¯·è¾“å…¥ä¸€ä¸ªæ­£å¸¸çš„å§“åã€‚"
        
        # éªŒè¯é€šè¿‡
        self.user_identity = name
        self.is_identity_verified = True
        return True, None
    
    def reset_identity(self):
        """é‡ç½®èº«ä»½éªŒè¯çŠ¶æ€"""
        self.user_identity = None
        self.is_identity_verified = False
        self.chat_terminated = False
        self.session_info = {}  # æ¸…ç©ºä¼šè¯ä¿¡æ¯
    
    def get_identity_prompt(self):
        """è·å–èº«ä»½ç¡®è®¤æç¤º"""
        style_prompts = {
            'formal': 'æ¬¢è¿ä½¿ç”¨ï¼ä¸ºäº†æ›´å¥½åœ°ä¸ºæ‚¨æœåŠ¡ï¼Œè¯·å…ˆå‘Šè¯‰æˆ‘æ‚¨çš„å§“åæˆ–æ˜µç§°ã€‚',
            'casual': f'å—¨ï½æˆ‘æ˜¯{config.virtual_human_name}ï¼è¯·å‘Šè¯‰æˆ‘ä½ çš„åå­—ï¼Œè¿™æ ·æˆ‘å°±çŸ¥é“æ€ä¹ˆç§°å‘¼ä½ äº†ï½ğŸ˜Š',
            'cute': f'ä½ å¥½å‘€ï½æˆ‘æ˜¯{config.virtual_human_name}ï¼å¯ä»¥å‘Šè¯‰æˆ‘ä½ çš„åå­—å—ï¼Ÿæˆ‘æƒ³è®¤è¯†ä½ å‘¢ï½ âœ¨'
        }
        return style_prompts.get(config.reply_style, 'è¯·è¾“å…¥æ‚¨çš„å§“åä»¥å¼€å§‹å¯¹è¯ã€‚')
    
    def get_termination_message(self):
        """è·å–èŠå¤©ç»ˆæ­¢æç¤ºä¿¡æ¯"""
        style_messages = {
            'formal': f'å¾ˆæŠ±æ­‰ï¼Œæˆ‘ä»¬çš„å¯¹è¯å·²è¾¾åˆ°å­˜å‚¨ä¸Šé™ï¼ˆ{config.chat_storage_limit}æ¡è®°å½•ï¼‰ã€‚è¯·æ¸…ç©ºèŠå¤©å†å²æˆ–é‡å¯åº”ç”¨ä»¥ç»§ç»­å¯¹è¯ã€‚æ„Ÿè°¢æ‚¨çš„ç†è§£ã€‚',
            'casual': f'å“å‘€ï½æˆ‘ä»¬èŠå¾—å¤ªå¤šäº†ï¼å·²ç»è¾¾åˆ°{config.chat_storage_limit}æ¡è®°å½•çš„ä¸Šé™äº† ğŸ˜… éœ€è¦æ¸…ç©ºä¸€ä¸‹èŠå¤©è®°å½•æ‰èƒ½ç»§ç»­å“¦ï½',
            'cute': f'å‘€ï½æˆ‘ä»¬èŠäº†å¥½å¤šå¥½å¤šè¯å‘¢ï¼å·²ç»æœ‰{config.chat_storage_limit}æ¡è®°å½•å•¦ (ï¼ï¹ï¼œ) éœ€è¦æ¸…ç†ä¸€ä¸‹å°è„‘è¢‹æ‰èƒ½ç»§ç»­èŠå¤©å“¦ï½'
        }
        return style_messages.get(config.reply_style, f'å¯¹è¯å·²è¾¾åˆ°å­˜å‚¨ä¸Šé™ï¼ˆ{config.chat_storage_limit}æ¡è®°å½•ï¼‰ï¼Œè¯·æ¸…ç©ºå†å²åç»§ç»­ã€‚')
    
    def detect_goodbye_intent(self, user_message):
        """æ£€æµ‹ç”¨æˆ·æ˜¯å¦æƒ³ç»“æŸèŠå¤©"""
        goodbye_keywords = [
            'å†è§', 'æ‹œæ‹œ', 'ç»“æŸ', 'é€€å‡º', 'ç¦»å¼€', 'ä¸‹çº¿', 'å…³é—­',
            'bye', 'goodbye', 'exit', 'quit', 'close', 'end',
            '88', '886', 'æ™šå®‰', 'ç¡è§‰', 'ä¼‘æ¯', 'èµ°äº†', 'å…ˆèµ°äº†',
            'ä¸èŠäº†', 'èŠå¤©ç»“æŸ', 'ç»“æŸèŠå¤©', 'åœæ­¢èŠå¤©'
        ]
        
        message_lower = user_message.lower().strip()
        return any(keyword in message_lower for keyword in goodbye_keywords)
    
    def get_response_sync(self, user_message):
        """è·å–AIå›å¤ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        try:
            # æ£€æŸ¥èŠå¤©æ˜¯å¦å·²ç»ˆæ­¢
            if self.chat_terminated:
                return self.get_termination_message()
            
            # æ£€æŸ¥èº«ä»½éªŒè¯
            if config.enable_identity_verification and not self.is_identity_verified:
                # å°è¯•éªŒè¯èº«ä»½
                is_valid, error_message = self.verify_identity(user_message)
                if is_valid:
                    welcome_messages = {
                        'formal': f'æ‚¨å¥½ï¼Œ{self.user_identity}ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚æœ‰ä»€ä¹ˆå¯ä»¥ä¸ºæ‚¨åšçš„å—ï¼Ÿ',
                        'casual': f'å—¨ {self.user_identity}ï¼å¾ˆå¼€å¿ƒè®¤è¯†ä½ ï½æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼ŸğŸ˜Š',
                        'cute': f'å“‡ï½åŸæ¥ä½ å«{self.user_identity}å‘€ï¼å¥½å¥½å¬çš„åå­—ï½æˆ‘æ˜¯{config.virtual_human_name}ï¼Œä»¥åè¯·å¤šå¤šæŒ‡æ•™å“¦ âœ¨'
                    }
                    # èº«ä»½éªŒè¯æˆåŠŸï¼Œè®°å½•åˆ°å†å²ä½†ä¸è°ƒç”¨AI
                    welcome_msg = welcome_messages.get(config.reply_style, f'æ‚¨å¥½ï¼Œ{self.user_identity}ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚')
                    # æ‰‹åŠ¨æ·»åŠ åˆ°å†å²è®°å½•
                    self.conversation_history.append({
                        'user': user_message,
                        'assistant': welcome_msg,
                        'timestamp': time.time()
                    })
                    return welcome_msg
                else:
                    # èº«ä»½éªŒè¯å¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯æç¤ºï¼Œä¸è°ƒç”¨AIä¹Ÿä¸è®°å½•å†å²
                    if error_message:
                        return error_message
                    else:
                        return self.get_identity_prompt()
            
            # æ£€æµ‹æ˜¯å¦æ˜¯å‘Šåˆ«æ„å›¾
            if self.detect_goodbye_intent(user_message):
                # å…ˆè·å–AIå›å¤
                if config.current_provider == 'openai':
                    response = self._call_openai_sync(user_message)
                elif config.current_provider == 'anthropic':
                    response = self._call_anthropic_sync(user_message)
                elif config.current_provider == 'deepseek':
                    response = self._call_deepseek_sync(user_message)
                elif config.current_provider == 'local':
                    response = self._call_local_sync(user_message)
                else:
                    response = self._get_mock_response(user_message)
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                self.add_to_history(user_message, response)
                
                # å½’æ¡£èŠå¤©è®°å½•
                self.clear_history('user_goodbye')
                
                return response
            
            # æ­£å¸¸å¤„ç†AIå›å¤
            if config.current_provider == 'openai':
                response = self._call_openai_sync(user_message)
            elif config.current_provider == 'anthropic':
                response = self._call_anthropic_sync(user_message)
            elif config.current_provider == 'deepseek':
                response = self._call_deepseek_sync(user_message)
            elif config.current_provider == 'local':
                response = self._call_local_sync(user_message)
            else:
                response = self._get_mock_response(user_message)
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.add_to_history(user_message, response)
            return response
        except Exception as e:
            print(f"AIè°ƒç”¨å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å›°æƒ‘ ğŸ˜… è¯·ç¨åå†è¯•è¯•å§ï¼"

    async def get_response(self, user_message):
        """è·å–AIå›å¤"""
        try:
            # æ£€æŸ¥èŠå¤©æ˜¯å¦å·²ç»ˆæ­¢
            if self.chat_terminated:
                return self.get_termination_message()
            
            # æ£€æŸ¥èº«ä»½éªŒè¯
            if config.enable_identity_verification and not self.is_identity_verified:
                # å°è¯•éªŒè¯èº«ä»½
                is_valid, error_message = self.verify_identity(user_message)
                if is_valid:
                    welcome_messages = {
                        'formal': f'æ‚¨å¥½ï¼Œ{self.user_identity}ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚æœ‰ä»€ä¹ˆå¯ä»¥ä¸ºæ‚¨åšçš„å—ï¼Ÿ',
                        'casual': f'å—¨ {self.user_identity}ï¼å¾ˆå¼€å¿ƒè®¤è¯†ä½ ï½æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼ŸğŸ˜Š',
                        'cute': f'å“‡ï½åŸæ¥ä½ å«{self.user_identity}å‘€ï¼å¥½å¥½å¬çš„åå­—ï½æˆ‘æ˜¯{config.virtual_human_name}ï¼Œä»¥åè¯·å¤šå¤šæŒ‡æ•™å“¦ âœ¨'
                    }
                    # èº«ä»½éªŒè¯æˆåŠŸï¼Œè®°å½•åˆ°å†å²ä½†ä¸è°ƒç”¨AI
                    welcome_msg = welcome_messages.get(config.reply_style, f'æ‚¨å¥½ï¼Œ{self.user_identity}ï¼å¾ˆé«˜å…´è®¤è¯†æ‚¨ã€‚')
                    # æ‰‹åŠ¨æ·»åŠ åˆ°å†å²è®°å½•
                    self.conversation_history.append({
                        'user': user_message,
                        'assistant': welcome_msg,
                        'timestamp': time.time()
                    })
                    return welcome_msg
                else:
                    # èº«ä»½éªŒè¯å¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯æç¤ºï¼Œä¸è°ƒç”¨AIä¹Ÿä¸è®°å½•å†å²
                    if error_message:
                        return error_message
                    else:
                        return self.get_identity_prompt()
            
            # æ£€æµ‹æ˜¯å¦æ˜¯å‘Šåˆ«æ„å›¾
            if self.detect_goodbye_intent(user_message):
                # å…ˆè·å–AIå›å¤
                if config.current_provider == 'openai':
                    response = await self._call_openai(user_message)
                elif config.current_provider == 'anthropic':
                    response = await self._call_anthropic(user_message)
                elif config.current_provider == 'deepseek':
                    response = await self._call_deepseek(user_message)
                elif config.current_provider == 'local':
                    response = await self._call_local(user_message)
                else:
                    response = self._get_mock_response(user_message)
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                self.add_to_history(user_message, response)
                
                # å½’æ¡£èŠå¤©è®°å½•
                self.clear_history('user_goodbye')
                
                return response
            
            # æ­£å¸¸å¤„ç†AIå›å¤
            if config.current_provider == 'openai':
                response = await self._call_openai(user_message)
            elif config.current_provider == 'anthropic':
                response = await self._call_anthropic(user_message)
            elif config.current_provider == 'deepseek':
                response = await self._call_deepseek(user_message)
            elif config.current_provider == 'local':
                response = await self._call_local(user_message)
            else:
                response = self._get_mock_response(user_message)
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.add_to_history(user_message, response)
            return response
        except Exception as e:
            print(f"AIè°ƒç”¨å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å›°æƒ‘ ğŸ˜… è¯·ç¨åå†è¯•è¯•å§ï¼"
    
    async def _call_openai(self, user_message):
        """è°ƒç”¨OpenAI API"""
        messages = [{"role": "system", "content": self.get_system_prompt()}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for conv in self.conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        messages.append({"role": "user", "content": user_message})
        
        headers = {
            'Authorization': f'Bearer {config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': config.model,
            'messages': messages,
            'max_tokens': config.max_tokens,
            'temperature': config.temperature,
            'stream': False
        }
        
        response = requests.post(
            f'{config.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content'].strip()
            return ai_response
        else:
            raise Exception(f"OpenAI APIé”™è¯¯: {response.status_code}")
    
    async def _call_anthropic(self, user_message):
        """è°ƒç”¨Anthropic API"""
        headers = {
            'x-api-key': config.api_key,
            'content-type': 'application/json',
            'anthropic-version': '2023-06-01'
        }
        
        # æ„å»ºå¯¹è¯å†å²
        conversation = self.get_system_prompt() + "\n\n"
        for conv in self.conversation_history[-5:]:
            conversation += f"Human: {conv['user']}\n\nAssistant: {conv['assistant']}\n\n"
        conversation += f"Human: {user_message}\n\nAssistant:"
        
        data = {
            'model': config.model,
            'max_tokens': config.max_tokens,
            'temperature': config.temperature,
            'messages': [{"role": "user", "content": conversation}]
        }
        
        response = requests.post(
            f'{config.base_url}/v1/messages',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['content'][0]['text'].strip()
            return ai_response
        else:
            raise Exception(f"Anthropic APIé”™è¯¯: {response.status_code}")
    
    async def _call_deepseek(self, user_message):
        """è°ƒç”¨DeepSeek API"""
        messages = [{"role": "system", "content": self.get_system_prompt()}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for conv in self.conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        messages.append({"role": "user", "content": user_message})
        
        headers = {
            'Authorization': f'Bearer {config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': config.model,
            'messages': messages,
            'max_tokens': config.max_tokens,
            'temperature': config.temperature,
            'stream': False
        }
        
        response = requests.post(
            f'{config.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content'].strip()
            return ai_response
        else:
            raise Exception(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
    
    async def _call_local(self, user_message):
        """è°ƒç”¨æœ¬åœ°æ¨¡å‹API"""
        messages = [{"role": "system", "content": self.get_system_prompt()}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for conv in self.conversation_history[-5:]:
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        messages.append({"role": "user", "content": user_message})
        
        headers = {'Content-Type': 'application/json'}
        if config.api_key:
            headers['Authorization'] = f'Bearer {config.api_key}'
        
        data = {
            'model': config.model,
            'messages': messages,
            'stream': False
        }
        
        response = requests.post(
            f'{config.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content'].strip()
            return ai_response
        else:
            raise Exception(f"æœ¬åœ°æ¨¡å‹APIé”™è¯¯: {response.status_code}")
    
    def _call_openai_sync(self, user_message):
        """è°ƒç”¨OpenAI APIï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        messages = [{"role": "system", "content": self.get_system_prompt()}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for conv in self.conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        messages.append({"role": "user", "content": user_message})
        
        headers = {
            'Authorization': f'Bearer {config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': config.model,
            'messages': messages,
            'max_tokens': config.max_tokens,
            'temperature': config.temperature,
            'stream': False
        }
        
        response = requests.post(
            f'{config.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content'].strip()
            return ai_response
        else:
            raise Exception(f"OpenAI APIé”™è¯¯: {response.status_code}")
    
    def _call_anthropic_sync(self, user_message):
        """è°ƒç”¨Anthropic APIï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        headers = {
            'x-api-key': config.api_key,
            'content-type': 'application/json',
            'anthropic-version': '2023-06-01'
        }
        
        # æ„å»ºå¯¹è¯å†å²
        conversation = self.get_system_prompt() + "\n\n"
        for conv in self.conversation_history[-5:]:
            conversation += f"Human: {conv['user']}\n\nAssistant: {conv['assistant']}\n\n"
        conversation += f"Human: {user_message}\n\nAssistant:"
        
        data = {
            'model': config.model,
            'max_tokens': config.max_tokens,
            'temperature': config.temperature,
            'messages': [{"role": "user", "content": conversation}]
        }
        
        response = requests.post(
            f'{config.base_url}/v1/messages',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['content'][0]['text'].strip()
            return ai_response
        else:
            raise Exception(f"Anthropic APIé”™è¯¯: {response.status_code}")
    
    def _call_deepseek_sync(self, user_message):
        """è°ƒç”¨DeepSeek APIï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        messages = [{"role": "system", "content": self.get_system_prompt()}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for conv in self.conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        messages.append({"role": "user", "content": user_message})
        
        headers = {
            'Authorization': f'Bearer {config.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': config.model,
            'messages': messages,
            'max_tokens': config.max_tokens,
            'temperature': config.temperature,
            'stream': False
        }
        
        response = requests.post(
            f'{config.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content'].strip()
            return ai_response
        else:
            raise Exception(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
    
    def _call_local_sync(self, user_message):
        """è°ƒç”¨æœ¬åœ°æ¨¡å‹APIï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        messages = [{"role": "system", "content": self.get_system_prompt()}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for conv in self.conversation_history[-5:]:
            messages.append({"role": "user", "content": conv['user']})
            messages.append({"role": "assistant", "content": conv['assistant']})
        
        messages.append({"role": "user", "content": user_message})
        
        headers = {'Content-Type': 'application/json'}
        if config.api_key:
            headers['Authorization'] = f'Bearer {config.api_key}'
        
        data = {
            'model': config.model,
            'messages': messages,
            'stream': False
        }
        
        response = requests.post(
            f'{config.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content'].strip()
            return ai_response
        else:
            raise Exception(f"æœ¬åœ°æ¨¡å‹APIé”™è¯¯: {response.status_code}")

    def _get_mock_response(self, user_message):
        """æ¨¡æ‹Ÿå›å¤ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        mock_responses = [
            f"ä½ å¥½ï¼æˆ‘æ˜¯{config.virtual_human_name}ï¼Œå¾ˆé«˜å…´å’Œä½ èŠå¤©ï¼ğŸ˜Š",
            "è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„é—®é¢˜å‘¢ï½æˆ‘æ­£åœ¨æ€è€ƒä¸­...",
            "å“‡ï¼Œä½ è¯´å¾—å¾ˆæœ‰é“ç†ï¼æˆ‘å­¦åˆ°äº†æ–°ä¸œè¥¿ âœ¨",
            "è®©æˆ‘æƒ³æƒ³...å—¯ï¼Œæˆ‘è§‰å¾—å¯èƒ½æ˜¯è¿™æ ·çš„...",
            "çœŸæ˜¯å¤ªæ£’äº†ï¼æ„Ÿè°¢ä½ å’Œæˆ‘åˆ†äº«è¿™äº› ğŸ’«"
        ]
        
        import random
        ai_response = random.choice(mock_responses)
        return ai_response
    
    def clear_history(self, end_reason='user_clear'):
        """æ¸…ç©ºå¯¹è¯å†å²å¹¶å½’æ¡£"""
        # å¦‚æœæœ‰èŠå¤©è®°å½•ä¸”ç”¨æˆ·å·²éªŒè¯èº«ä»½ï¼Œåˆ™å½’æ¡£åˆ°æ•°æ®åº“
        if self.conversation_history and self.is_identity_verified:
            try:
                # è½¬æ¢å†å²è®°å½•æ ¼å¼ä»¥é€‚é…æ•°æ®åº“
                formatted_history = []
                for conv in self.conversation_history:
                    formatted_history.append({
                        'role': 'user',
                        'content': conv['user']
                    })
                    formatted_history.append({
                        'role': 'assistant', 
                        'content': conv['assistant']
                    })
                
                # å½’æ¡£èŠå¤©è®°å½•
                success = chat_archive_service.archive_chat_session(
                    conversation_history=formatted_history,
                    user_identity=self.user_identity,
                    ai_provider=config.current_provider,
                    ai_model=config.model,
                    end_reason=end_reason,
                    browser_info=self.session_info.get('browser_info'),
                    ip_address=self.session_info.get('ip_address'),
                    location_info=self.session_info.get('location_info')
                )
                
                if success:
                    print(f"èŠå¤©è®°å½•å·²æˆåŠŸå½’æ¡£åˆ°æ•°æ®åº“ï¼Œç”¨æˆ·: {self.user_identity}, æ¶ˆæ¯æ•°: {len(self.conversation_history)}")
                else:
                    print(f"èŠå¤©è®°å½•å½’æ¡£å¤±è´¥ï¼Œç”¨æˆ·: {self.user_identity}, æ¶ˆæ¯æ•°: {len(self.conversation_history)}")
            except Exception as e:
                print(f"å½’æ¡£èŠå¤©è®°å½•å¤±è´¥: {e}")
        
        # æ¸…ç©ºå†…å­˜ä¸­çš„å†å²è®°å½•
        self.conversation_history = []
        self.reset_identity()  # é‡ç½®èº«ä»½éªŒè¯çŠ¶æ€
    
    def get_history(self):
        """è·å–å¯¹è¯å†å²"""
        return {
            'history': self.conversation_history,
            'user_identity': self.user_identity,
            'is_identity_verified': self.is_identity_verified,
            'chat_terminated': self.chat_terminated,
            'chat_count': len(self.conversation_history),
            'chat_limit': config.chat_storage_limit,
            'session_info': self.session_info
        }
    
    def set_session_info(self, browser_info: str = None, ip_address: str = None, location_info: str = None):
        """è®¾ç½®ä¼šè¯ä¿¡æ¯"""
        if browser_info:
            self.session_info['browser_info'] = browser_info
        if ip_address:
            self.session_info['ip_address'] = ip_address
        if location_info:
            self.session_info['location_info'] = location_info

# å…¨å±€AIæ¨¡å‹ç®¡ç†å™¨å®ä¾‹
ai_manager = AIModelManager() 